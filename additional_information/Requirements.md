# Requirements
Document requirements and split it up into increments

## Increment 1
[ ] Request price and title from amazon
[ ] Save prices to csv file

## Increment 2
[ ] Implement user and article management
[ ] In total 4 Tables should be there
    -- Articles
    -- Users
    -- Collected prices
    -- Connection between Users and Articles
    
## Increment 3
[ ] Send mail notifications

## Increment 4
[ ] Change datastorage and evaluation to sqlite3 database

## Increment 5
[ ] Automate scraping on regular intervals
[ ] Run script on server / cloud
[ ] Manage connection between server / cloud and local database
[ ] If not possible on server, provide data in google drive or sth. to collaborative collect the data

## Increment 6
[ ] Create evaluations of articles
[ ] Send weekly reports about articles for user

## Increment 7
[ ] Extend User and Article Management with more functionalities

## Increment 8
[ ] Create UI



# Sources and ideas

https://towardsdatascience.com/scraping-multiple-amazon-stores-with-python-5eab811453a8
https://scrapy.org/
https://blog.datahut.co/tutorial-how-to-scrape-amazon-data-using-python-scrapy/
http://docs.pyspider.org/en/latest/